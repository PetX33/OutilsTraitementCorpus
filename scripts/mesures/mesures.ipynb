{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perrine/Desktop/Master_S2/OutilTraitementCorpus/otc_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy, stanza\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 21:24:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 211MB/s]                     \n",
      "2024-04-23 21:24:35 INFO: Downloaded file to /Users/perrine/stanza_resources/resources.json\n",
      "2024-04-23 21:24:36 INFO: Loading these models for language: ar (Arabic):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | padt          |\n",
      "| mwt       | padt          |\n",
      "| pos       | padt_charlm   |\n",
      "| lemma     | padt_nocharlm |\n",
      "| depparse  | padt_charlm   |\n",
      "| ner       | aqmar_charlm  |\n",
      "=============================\n",
      "\n",
      "2024-04-23 21:24:36 INFO: Using device: cpu\n",
      "2024-04-23 21:24:36 INFO: Loading: tokenize\n",
      "2024-04-23 21:24:36 INFO: Loading: mwt\n",
      "2024-04-23 21:24:36 INFO: Loading: pos\n",
      "2024-04-23 21:24:36 INFO: Loading: lemma\n",
      "2024-04-23 21:24:36 INFO: Loading: depparse\n",
      "2024-04-23 21:24:36 INFO: Loading: ner\n",
      "2024-04-23 21:24:37 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Loading SpaCy models\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")  # English\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")  # Spanish\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")  # German\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")  # French\n",
    "nlp_ru = spacy.load(\"ru_core_news_sm\")  # Russian\n",
    "nlp_zh = spacy.load(\"zh_core_web_sm\")  # Chinese\n",
    "nlp_ja = spacy.load(\"ja_core_news_sm\")  # Japanese\n",
    "nlp_ko = spacy.load(\"ko_core_news_sm\")  # Korean\n",
    "\n",
    "nlp_ar = stanza.Pipeline(lang='ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lang):\n",
    "    if lang == 'ar':\n",
    "        doc = nlp_ar(text)\n",
    "        return [word.text for sent in doc.sentences for word in sent.words]\n",
    "    else:\n",
    "        nlp = globals()[f\"nlp_{lang}\"]\n",
    "        doc = nlp(text)\n",
    "        return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenisation** : \n",
    "- Chaque document est tokenisé selon la langue à l'aide des modèles de NLP correspondants. Les tokens sont les mots dans le cas des langues occidentales et des unités plus complexes pour des langues comme le chinois ou le japonais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data):\n",
    "    language_data = defaultdict(list)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        tokens = tokenize(row['Text'], row['Label'])\n",
    "        language_data[row['Label']].append(tokens)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for lang, tokens_list in language_data.items():\n",
    "        total_words = sum(len(tokens) for tokens in tokens_list)\n",
    "        total_samples = len(tokens_list)\n",
    "        unique_words = len(set(word for tokens in tokens_list for word in tokens))\n",
    "        \n",
    "        average_words_per_sample = total_words / total_samples if total_samples else 0\n",
    "        lexical_diversity = unique_words / total_words if total_words else 0\n",
    "\n",
    "        results[lang] = {\n",
    "            'Average Words per Sample': average_words_per_sample,\n",
    "            'Lexical Diversity': lexical_diversity\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métriques calculées** :\n",
    "- **Moyenne des mots par échantillon** : Cela donne une idée de la longueur moyenne des textes pour chaque langue.\n",
    "- **Diversité lexicale** : C'est le rapport entre le nombre de mots uniques et le nombre total de mots dans les échantillons de chaque langue. Une valeur plus élevée indique une plus grande richesse lexicale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ko': {'Average Words per Sample': 191.4, 'Lexical Diversity': 0.625914315569488}, 'ar': {'Average Words per Sample': 102.2, 'Lexical Diversity': 0.46868884540117417}, 'fr': {'Average Words per Sample': 1230.9, 'Lexical Diversity': 0.2210577626127224}, 'zh': {'Average Words per Sample': 501.7, 'Lexical Diversity': 0.3060593980466414}, 'es': {'Average Words per Sample': 389.95, 'Lexical Diversity': 0.3341454032568278}, 'ru': {'Average Words per Sample': 1028.65, 'Lexical Diversity': 0.3505079473095805}, 'de': {'Average Words per Sample': 502.55, 'Lexical Diversity': 0.3381753059397075}, 'ja': {'Average Words per Sample': 593.2, 'Lexical Diversity': 0.2226062036412677}, 'en': {'Average Words per Sample': 1418.55, 'Lexical Diversity': 0.20584399562933983}}\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../../data/csv/data_balanced.csv')\n",
    "\n",
    "# Compute metrics\n",
    "metrics = calculate_metrics(data)\n",
    "\n",
    "# Display the metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des Résultats** : \n",
    "- Les résultats sont stockés dans un dictionnaire et imprimés. Vous pouvez également les visualiser en utilisant matplotlib ou une autre bibliothèque de visualisation pour mieux comprendre les distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En analysant les données fournies sur la reconnaissance de la langue d'un texte à partir des pages Wikipédia, je m'intéresse particulièrement au nombre moyen de mots par échantillon et à la diversité lexicale de chaque langue. Ces indicateurs me permettent d'évaluer la complexité et la richesse du vocabulaire utilisé dans ces corpus linguistiques divers. Voici mon interprétation personnelle des résultats obtenus pour chaque langue :\n",
    "\n",
    "1. **Coréen (ko)** : Le coréen affiche un nombre moyen de mots par échantillon de 191.4 et une diversité lexicale de 0.626. Ce niveau élevé de diversité lexicale suggère une grande variété de mots utilisés, même dans des textes plus courts, ce qui reflète la complexité structurelle de la langue coréenne.\n",
    "\n",
    "2. **Arabe (ar)** : Avec une moyenne de 102.2 mots par échantillon et une diversité lexicale de 0.469, l'arabe semble utiliser un vocabulaire varié, même dans un contexte de rédaction relativement concis. Cela pourrait être dû à la riche morphologie de l'arabe qui permet une grande variabilité dans l'utilisation des mots.\n",
    "\n",
    "3. **Français (fr)** : Les textes en français sont particulièrement longs, avec une moyenne de 1230.9 mots par échantillon, mais présentent une faible diversité lexicale de 0.221. Cela indique une utilisation répétitive du vocabulaire dans de longs articles, typique des discussions approfondies sur des sujets complexes.\n",
    "\n",
    "4. **Chinois (zh)** : Le chinois montre une moyenne de 501.7 mots par échantillon avec une diversité lexicale de 0.306. Je trouve que cette langue utilise efficacement un vocabulaire varié même dans des textes de longueur modérée, ce qui est caractéristique de ses traits logographiques.\n",
    "\n",
    "5. **Espagnol (es)** : L'espagnol présente une moyenne de mots par échantillon de 389.95 avec une diversité lexicale de 0.334. J'observe un bon équilibre entre la longueur des textes et une variété raisonnable de vocabulaire, ce qui pourrait refléter une tendance à la descriptivité tout en restant accessible.\n",
    "\n",
    "6. **Russe (ru)** : Avec une moyenne élevée de 1028.65 mots et une diversité lexicale de 0.351, le russe semble exploiter un vocabulaire riche dans des descriptions détaillées, ce que j'attribue à la nature descriptive de la langue et à son système morphologique complexe.\n",
    "\n",
    "7. **Allemand (de)** : Les textes allemands, avec 502.55 mots en moyenne et une diversité lexicale de 0.338, montrent une préférence pour l'utilisation de vocabulaire varié dans des textes de longueur moyenne. Je pense que cela est dû à la capacité de l'allemand à former des mots composés, enrichissant ainsi son lexique.\n",
    "\n",
    "8. **Japonais (ja)** : Avec 593.2 mots par échantillon et une diversité lexicale de 0.223, le japonais semble favoriser des textes modérément longs avec une utilisation répétitive de termes spécifiques. Cette caractéristique reflète, à mon avis, la structure grammaticale et le style formel du japonais.\n",
    "\n",
    "9. **Anglais (en)** : L'anglais se distingue avec le plus haut nombre moyen de mots (1418.55) et la diversité lexicale la plus basse (0.206). Cela me suggère une tendance à des textes très longs avec une utilisation limitée de vocabulaire diversifié, ce qui peut indiquer une norme de rédaction détaillée et exhaustive typique de Wikipédia en anglais.\n",
    "\n",
    "En résumé, ces observations montrent comment chaque langue utilise ses structures et son vocabulaire pour refléter ses caractéristiques uniques. Les différences notées dans la longueur des textes et la diversité lexicale entre les langues peuvent également être influencées par les spécificités des articles de Wikipédia, qui varient selon le sujet et le style de rédaction propre à chaque communauté linguistique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
