{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_csv(folder, folder_csv):\n",
    "    data_by_language = defaultdict(list)\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        # print(file)\n",
    "        lang = file.split(\"_\")[0]\n",
    "        with open(os.path.join(folder, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        if text:\n",
    "            data_by_language[lang].append(text)\n",
    "    \n",
    "    filtered_data_by_language = {lang: lines for lang, lines in data_by_language.items() if len(lines) > 2}\n",
    "    balanced_data = []\n",
    "\n",
    "    for lang, lines in filtered_data_by_language.items():\n",
    "        if lines:\n",
    "            balanced_data.extend((lang, line) for line in lines)\n",
    "\n",
    "    df_balanced = pd.DataFrame(balanced_data, columns=[\"Label\", \"Text\"])\n",
    "    os.makedirs(folder_csv, exist_ok=True)\n",
    "    df_balanced.to_csv(os.path.join(folder_csv, \"data.csv\"), index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je définis une fonction appelée `create_balanced_csv` qui prend deux paramètres : `folder` et `folder_csv`. `folder` est le chemin du dossier contenant les fichiers textuels que je veux analyser, et `folder_csv` est le chemin du dossier où je souhaite enregistrer le fichier CSV final.\n",
    "\n",
    "Voici comment je m'organise pour traiter les données :\n",
    "\n",
    "1. **Organisation des données par langue** :\n",
    "   - Je commence par créer un dictionnaire `data_by_language` en utilisant `defaultdict(list)`. Cela me permet de collecter des listes de textes classées par langue.\n",
    "   - Je parcours tous les fichiers dans le dossier spécifié avec `os.listdir(folder)`. Pour chaque fichier, je détermine la langue en extrayant la première partie du nom du fichier (avant le premier '_'). Cela suppose que chaque fichier est nommé avec le format \"langue_titre.txt\".\n",
    "   - J'ouvre chaque fichier en lecture, en utilisant son chemin complet et l'encodage UTF-8, puis je lis son contenu. Si le contenu n'est pas vide, je l'ajoute à la liste correspondant à sa langue dans `data_by_language`.\n",
    "\n",
    "2. **Filtrage des langues avec suffisamment de données** :\n",
    "   - Une fois tous les fichiers lus, je filtre les langues pour ne conserver que celles ayant plus de deux textes. Cela est réalisé avec une compréhension de dictionnaire qui crée `filtered_data_by_language` en vérifiant la longueur des listes pour chaque langue.\n",
    "\n",
    "3. **Création d'un ensemble de données équilibré** :\n",
    "   - Pour chaque langue ayant passé le filtre, je crée des paires (langue, texte) pour chaque texte disponible. J'utilise une expression génératrice pour ajouter ces paires à la liste `balanced_data`.\n",
    "\n",
    "4. **Conversion en DataFrame et enregistrement en CSV** :\n",
    "   - Je convertis la liste `balanced_data` en un DataFrame Pandas, `df_balanced`, avec des colonnes \"Label\" pour la langue et \"Text\" pour le texte.\n",
    "   - Je m'assure que le dossier de destination `folder_csv` existe (et je le crée s'il n'existe pas) avec `os.makedirs`.\n",
    "   - Enfin, je sauvegarde le DataFrame dans un fichier CSV nommé \"data_balanced.csv\" dans le dossier `folder_csv`, en m'assurant que l'index n'est pas inclus dans le fichier CSV et que l'encodage est UTF-8.\n",
    "\n",
    "Cette fonction `create_balanced_csv` me permet donc de regrouper des textes par langue, de filtrer les langues ayant une quantité minimale de données, et de stocker ces informations de manière structurée dans un fichier CSV, facilitant ainsi les analyses futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_csv(csv, folder_csv):\n",
    "    df_train, df_test = train_test_split(csv, test_size=0.2, random_state=42)\n",
    "    df_train.to_csv(os.path.join(folder_csv, \"data_train.csv\"), index=False, encoding=\"utf-8\")\n",
    "    df_test.to_csv(os.path.join(folder_csv, \"data_test.csv\"), index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je définis une fonction appelée `create_train_test_csv` qui prend deux paramètres : `csv` et `folder_csv`. Le premier, `csv`, est un DataFrame qui contient les données, tandis que `folder_csv` est le chemin du dossier où je souhaite enregistrer les fichiers CSV résultants pour les ensembles d'entraînement et de test.\n",
    "\n",
    "Voici comment je procède pour diviser les données et les enregistrer :\n",
    "\n",
    "1. **Division des données en ensembles d'entraînement et de test** :\n",
    "   - J'utilise la fonction `train_test_split` de la bibliothèque scikit-learn pour diviser le DataFrame `csv` en deux sous-ensembles. Je spécifie `test_size=0.2` pour allouer 20% des données au jeu de test, tandis que les 80% restants constitueront le jeu d'entraînement. L'argument `random_state=42` est utilisé pour garantir la reproductibilité du découpage des données.\n",
    "\n",
    "2. **Enregistrement des ensembles d'entraînement et de test en CSV** :\n",
    "   - Une fois les données divisées, je sauvegarde l'ensemble d'entraînement dans un fichier CSV nommé \"data_train.csv\" et l'ensemble de test dans un fichier \"data_test.csv\". Ces fichiers sont enregistrés dans le dossier spécifié par `folder_csv`.\n",
    "   - Pour chaque sauvegarde, je spécifie `index=False` pour ne pas inclure l'index du DataFrame dans le fichier CSV et `encoding='utf-8'` pour assurer que le fichier est encodé correctement, ce qui est important pour le traitement ultérieur des données, surtout si elles contiennent des caractères non ASCII.\n",
    "\n",
    "Cette fonction `create_train_test_csv` permet de préparer efficacement les données pour des phases ultérieures de modélisation en machine learning, en s'assurant que les données sont correctement réparties et enregistrées de manière à faciliter leur accès et leur utilisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    folder_csv = \"../../../data/csv/\"\n",
    "    folder_txt_files = \"../../../data/clean/\"\n",
    "    create_balanced_csv(folder_txt_files, folder_csv)\n",
    "    df_balanced = pd.read_csv(os.path.join(folder_csv, \"data.csv\"), encoding=\"utf-8\")\n",
    "    create_train_test_csv(df_balanced, folder_csv)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
